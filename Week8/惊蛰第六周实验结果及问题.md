# 惊蛰第六周学习结果及问题

[TOC]

## 1.单层全连接SNN识别MNIST实验结果

### 1.1 学习过程

学习参考资料：

- spikingjelly中的相关教程
- spikingjelly中提到的完整源码lif_fc_mnist.py

对这些内容学习后，对如何搭建SNN以及如何进行实验都有了更清楚的认识。与搭建传统网络的步骤类似，SNN网络也需要定义网络结构，定义试验需要的参数以及编写实验流程。同时在学习过程中也学会了如何存储结果，以及一些结果展示的方法。

### 1.2 实验结果

第一次实验结果如下：、

参数设置：

```python
Namespace(T=50, device='cuda:0', b=32, epochs=20, j=2, data_dir='mnist-data', out_dir='./logs', resume=None, amp=False, opt='adam', momentum=0.9, lr=0.001, tau=2.0)
```

实验结果，进行了20轮实验，平均每一轮的运行时间在70s附近：

![1660040890265](C:\Users\17799\AppData\Roaming\Typora\typora-user-images\1660040890265.png)

准确率最高在92.67%

第二次实验结果如下：

这次尝试开启**自动混合精度**，但是实验所花费的时间并没有明显减少，甚至时间还有增加：

![1660052261354](C:\Users\17799\AppData\Roaming\Typora\typora-user-images\1660052261354.png)

第三次实验结果如下：

这次关闭自动混合精度，但是将T设置为100：

```python
Namespace(T=100, device='cuda:0', b=32, epochs=20, j=2, data_dir='mnist-data', out_dir='./logs', resume=None, amp=False, opt='adam', momentum=0.9, lr=0.001, tau=2.0)
```

实验结果如下：

![1660055607439](C:\Users\17799\AppData\Roaming\Typora\typora-user-images\1660055607439.png)

可以发现实验的运行时间大致为原来两倍，且准确率最高为92.75%

## 2.遇到的问题及解决

### 2.1 版本问题

在学习过程中，教程给的是13版本的，而自己通过pip安装的是12版本，学习有些许不方便，尝试安装了13版：

![1659954692778](C:\Users\17799\AppData\Roaming\Typora\typora-user-images\1659954692778.png)

但是更新后还是12版本：

![1659945952899](C:\Users\17799\AppData\Roaming\Typora\typora-user-images\1659945952899.png)

考虑可能是以前安装过的问题，所以说通过代码，卸载后再安装：

```
pip uninstall spikingjelly
cd spikingjelly
python setup.py install
```

版本更新成功：

![1659946070193](C:\Users\17799\AppData\Roaming\Typora\typora-user-images\1659946070193.png)

### 2.2 没有安装tensorboard

在学习监视器环节时，导包出现错误：

![1659967688039](C:\Users\17799\AppData\Roaming\Typora\typora-user-images\1659967688039.png)

提示没有安装tensorboard，安装完毕：

![1659967997175](C:\Users\17799\AppData\Roaming\Typora\typora-user-images\1659967997175.png)

### 2.3 encoding

在学习单层全连接SNN进行手写体识别时，需要泊松编码器：

```python
# 泊松编码器
encoder = encoding.PoissonEncoder()
```

但是之前没有了解过encoding包的知识，因此了解了一下：

spiking neural network 神经元的输入和输出都是0,1序列，·但是图像，语音等数据都是离散值，因此需要编码。

比如泊松[编码器](https://so.csdn.net/so/search?q=编码器&spm=1001.2101.3001.7020)的举例，泊松编码器将输入数据 `x` 编码为发放次数分布符合泊松过程的脉冲序列，注意x需要归一化到[0,1]之间。输入是512*512的灰度图像x，输出spike的大小是[20,512,512]的0,1矩阵。

所得到的矩阵与画出的图像：

![1660020415039](C:\Users\17799\AppData\Roaming\Typora\typora-user-images\1660020415039.png)

![1660020421381](C:\Users\17799\AppData\Roaming\Typora\typora-user-images\1660020421381.png)

### 2.4 自动混合精度没有加速运算

在实验中，开启自动混合运算后，运算时间甚至有所增加，上网查阅了相关资料：

![1660052591786](C:\Users\17799\AppData\Roaming\Typora\typora-user-images\1660052591786.png)

根据知乎相关用户的评论，大多数情况都是自动混合精度的方式减慢了一些速度，但是让**显存占用下降了一半**，减少显存占用可以考虑该方式。

## 参考资料

[1]  [PyTorch的自动混合精度（AMP） - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/165152789) 