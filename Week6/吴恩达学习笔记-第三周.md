# 吴恩达学习笔记-第三周

[TOC]



## 一、ML策略

### 1.设定目标

##### 1.1 单数评价指标

通过设置单数评价指标来判断模型的优异程度。

其中准确率意味着对一个样本的判断正确与否的能力，召回率意味着对于许多样本，分类器有多少百分比可以正确的识别出来(多少比率的真猫被正确的识别出来了)。但是这两个指标在一起往往不好对模型进行评判。

通常使用**F1分数**，即精准率P和召回率R的一种平均值。公示如下：

![1659014071933](C:\Users\17799\AppData\Roaming\Typora\typora-user-images\1659014071933.png)

并且平均值通常是一个评判模型的好方法。

##### 1.2 满足和优化指标

通过设置满足指标和优化指标，我们就有了挑选“最优”分类器的明确方向。一个比较关键的指标设置为满足指标，而其他目标就是优化指标，通过这种方式来选择自己最想要的指标方向。

##### 1.3 训练/开发/测试分布

开发集(dev set)也被称为development set，也被称为交叉验证集。使用开发集来评估不同的想法，并提高在开发集上的表现性能。

在设置开发集和测试集时，将所有的数据随机打乱然后分为开发和测试集。

##### 1.4 开发和测试集的大小和指标

测试集的作用，主要是在系统开发完成后，帮我们评估最终系统的性能。因此测试集的大小应该能保证对系统整体性能评估的**高置信度**。此时只需要1万-10万间的数据。

测试集，可以在上线前得到对系统性能的无偏估计。

##### 1.5 何时更改开发/测试集和指标

当你的评估指标无法正确衡量算法之间的优劣排序时，你应该改变评估指标或者要改变开发集或测试集。其中一个修改评估指标的方法是加个权重项。如果在指标上表现很好，在当前开发集和测试集上表现很好，但你的实际应用程序表现不好，那么就需要修改指标和开发测试集，改变你的开发测试集，让你的数据更能反映实际需要处理的数据。

### 2.与人的表现相比

##### 2.1 可避免的误差

假如人对猫的识别错误率，为1%，而训练集的错误率为8%，开发集的错误率为10%，这时就需要减少偏差，比如训练更大的神经网络或者跑久一点梯度下降，看看是否可以减少训练误差。假如人对猫的识别错误率为7.5%，而训练集的错误率仍然为8%，开发集的错误率仍然为10%，此时你可能更希望减少学习算法的方差，比如可以试试正则化，让你的开发误差更接近你的训练误差。

贝叶斯误差和训练集误差的差值称为可避免偏差，如下图。根据人类水平误差(human-level error)，理解你对贝叶斯误差的估计，你就可以在不同的场景中专注于不同的策略，使用避免偏差策略还是使用避免方差策略。

##### 2.2 超越人类水平表现

非自然感知问题(natural perception problems)，如Online advertising、Product recommendations、Logistics(predicting transit time)、Loan approvals等，即不是计算机视觉或语音识别或自然语言处理问题，较容易超越人类水平。人们在自然感知问题中往往表现非常好。所以有可能，对计算机来说，在自然感知任务的表现要超越人类要更难一些。

##### 2.3 提高模型性能

一个好的模型性能目标：

①很好地拟合训练集，得到较低的可避免偏差

②很好地推广到开发集或者测试集，即方差不太大

减少偏差可使用的方法：

训练更大的模型、训练时间更长一些；使用更好的优化算法，比如momentum、RMSProp；使用更好的算法，比如Adam；或者可以试试寻找更好的新神经网络架构，更好的超参数；改变激活函数，改变层数或隐藏单元数；试用其它模型或其它模型架构，如循环神经网络和卷积神经网络。 

减少方差可使用方法：

收集更多数据去训练；尝试正则化，包括L2正则化和Dropout，数据增强；尝试不同的神经网络架构，超参数搜索。 

### 3.误差分析

##### 3.1 进行误差分析

通过人工检查机器学习模型得出的结果中出现的一些错误，有助于深入了解下一步要进行的工作。这个过程被称作**错误分析（Error Analysis）**。 

可以从分类错误的样本中统计出狗的样本数量。根据狗样本所占的比重来判断这一问题的重要性。假如狗类样本所占比重仅为 5%，那么即使花费几个月的时间来提升模型对狗的识别率，改进后的模型错误率并没有显著改善；而如果错误样本中狗类所占比重为 50%，那么改进后的模型性能会有较大的提升。因此，花费更多的时间去研究能够精确识别出狗的算法是值得的。

观察错误标记的例子，看看假阳性(false positives)和假阴性(false negatives)，统计属于不同错误类型的错误数量。在这个过程中，你可能会得到启发，归纳出新的误差类型。总之，通过统计不同错误标记类型占总数的百分比可以帮你发现哪些问题需要优先解决或者给你构思新优化方向的灵感。

##### 3.2 清理错误标注的数据

在监督式学习中，训练样本有时候会出现输出Y标注错误的情况，即incorrectly labeled examples。 

如果这些label标错的情况是随机性的，DL算法对其包容性是比较强的，即健壮性好，一般可以直接忽略，无需修复。然而，如果是**系统错误（systematic errors）**，这将对DL算法造成影响，降低模型性能。 

若错误标标注标签所占比例较低，这种情况下，可以忽略incorrectly labeled data。但是，如果有incorrectly labeled data的存在，当不同算法错误率比较接近的时候，我们无法仅仅根据验证集上的误差准确指出哪个算法模型更好，必须修正incorrectly labeled data。  

此外，在修正时，不管用什么修正手段，都要同时作用到开发集和测试集上，因为开发集和测试集必须来自相同的分布。其次，你要考虑同时检验算法本应判断错误却判断正确的样本。 

##### 3.3 构建系统并进行迭代

如果你正在开发全新的机器学习应用，你应该尽快建立你的第一个系统原型，然后快速迭代：

①快速设立开发集/测试集和指标，这样就决定了你的目标所在。如果你的目标定错了，之后改也是可以的，但一定要设立某个目标。

②然后快速搭好一个机器学习系统原型，然后找到训练集，训练一下，看看效果，开始理解你的算法表现如何，在开发集/测试集你的评估指标表现如何。

③当你建立第一个系统后，你就可以用到偏差/方差分析，误差分析，来确定下一步优先做什么。

### 4.训练和验证/测试集不匹配

##### 4.1 训练和测试的不同分布

有时，我们很难得到来自同一个分布的训练集和验证/测试集。还是以猫识别作为例子，我们的训练集可能由网络爬虫得到，图片比较清晰，而且规模较大（例如 20 万）；而验证/测试集可能来自用户手机拍摄，图片比较模糊，且数量较少（例如 1 万），难以满足作为训练集时的规模需要。 

![1659025259075](C:\Users\17799\AppData\Roaming\Typora\typora-user-images\1659025259075.png)

虽然验证/测试集的质量不高，但是机器学习模型最终主要应用于识别这些用户上传的模糊图片。考虑到这一点，在划分数据集时，可以将 20 万张网络爬取的图片和 5000 张用户上传的图片作为训练集，而将剩下的 5000 张图片一半作验证集，一半作测试集。

比起混合数据集所有样本再随机划分，这种分配方法虽然使训练集分布和验证/测试集的分布并不一样，但是能保证验证/测试集更接近实际应用场景，在长期能带来更好的系统性能。

##### 4.2 不匹配数据分布的偏差

当你的训练集来自和开发集、测试集不同分布时分析偏差和方差的方式可能不一样。 在可能存在训练集和验证/测试集分布不一致的情况下，为了解决这个问题，我们可以再定义一个训练-验证集（Training-dev Set）。训练-验证集和训练集的分布相同（或者是训练集分割出的子集），但是不参与训练过程。 

训练-开发集：随机打乱训练集，然后分出一部分训练集作为训练-开发集，即训练集和训练-开发集来自同一分布，但是训练-开发集不会作为训练集的一部分，不会进行网络的后向传播中。 

然后分析训练集误差、训练-开发集误差、开发集误差，从中会总结是可避免的偏差、方差还是数据不匹配导致的。

##### 4.3 解决数据不匹配问题

解决数据不匹配的两种方法：

- 做误差分析，尝试了解训练集和验证/测试集的具体差异（主要是人工查看训练集和验证集的样本）；
- 尝试将训练数据调整得更像验证集，或者收集更多类似于验证/测试集的数据。

如果你打算将训练数据调整得更像验证集，可以使用的一种技术是人工合成数据。我们以语音识别问题为例，实际应用场合（验证/测试集）是包含背景噪声的，而作为训练样本的音频很可能是清晰而没有背景噪声的。为了让训练集与验证/测试集分布一致，我们可以给训练集人工添加背景噪声，合成类似实际场景的声音。

人工合成数据能够使数据集匹配，从而提升模型的效果。但需要注意的是，不能给每段语音都增加同一段背景噪声，因为这样模型会对这段背景噪音出现过拟合现象，使得效果不佳。

### 5.多项任务学习

##### 5.1 迁移学习

**迁移学习（Tranfer Learning）**是通过将已训练好的神经网络模型的一部分网络结构应用到另一模型，将一个神经网络从某个任务中学到的知识和经验运用到另一个任务中，以显著提高学习任务的性能。

例如，我们将为猫识别器构建的神经网络迁移应用到放射科诊断中。因为猫识别器的神经网络已经学习到了有关图像的结构和性质等方面的知识，所以只要先删除神经网络中原有的输出层，加入新的输出层并随机初始化权重系数（![W，b](https://private.codecogs.com/gif.latex?W%25uFF0Cb),![b](https://private.codecogs.com/gif.latex?b)），随后用新的训练集进行训练，就完成了以上的迁移学习。 

迁移学习一般有如下两种情况：

①如果新的数据集很小，可能只需要重新训练输出层前的最后一层的权重，并保持其他参数不变 

②如果有足够多的数据，可以只保留网络结构，重新训练神经网络中所有层的系数。这时初始权重由之前的模型训练得到，这个过程称为**预训练（Pre-Training）**，之后的权重更新过程称为**微调（Fine-Tuning）**。 

当然，同时也可以不止加入一个新的输出层，而是多向神经网络加几个新层。

一般在以下几种情况下进行迁移学习：

①两个任务有同样的输入（比如都是图像或者都是音频）；

②**拥有更多数据的任务迁移到数据较少的任务**；

③某一任务的低层次特征（底层神经网络的某些功能）对另一个任务的学习有帮助。

##### 5.2 多任务学习

迁移学习中的步骤是串行的；而多任务学习（Multi-Task Learning）使用单个神经网络模型，利用共享表示采用并行训练同时学习多个任务。多任务学习的基本假设是多个任务之间具有相关性，并且任务之间可以利用相关性相互促进。例如，属性分类中，抹口红和戴耳环有一定的相关性，单独训练的时候是无法利用这些信息，多任务学习则可以利用任务相关性联合提高多个属性分类的精度。

多任务学习是使用单个神经网络模型来实现多个任务。实际上，也可以分别构建多个神经网络来实现。多任务学习中可能存在训练样本 Y 某些标签空白的情况，这不会影响多任务学习模型的训练。 

多任务学习和 Softmax 回归的区别是，**Softmax 回归的输出向量 y 中只有一个元素为 1；而多任务学习的输出向量 y 中可以有多个元素为 1**。 

一般用在以下几种情况：

①训练的一组任务可以共用低层次特征；

②通常，每个任务的数据量接近；

③能够训练一个足够大的神经网络，以同时做好所有的工作。多任务学习会降低性能的唯一情况（即和为每个任务训练单个神经网络相比性能更低的情况）是神经网络还不够大。

在多任务深度网络中，低层次信息的共享有助于减少计算量，同时共享表示层可以使得几个有共性的任务更好的结合相关性信息，任务特定层则可以单独建模任务特定的信息，实现共享信息和任务特定信息的统一。但是在实践中，多任务学习的使用频率要远低于迁移学习。计算机视觉领域中的物体识别是一个多任务学习的例子。 

### 6.端到端深度学习

##### 6.1 理解端到端深度学习

在传统的机器学习分块模型中，每一个模块处理一种输入，然后其输出作为下一个模块的输入，构成一条流水线。而端到端深度学习，只用一个单一的神经网络模型来实现所有的功能。它将所有模块混合在一起，只关心输入和输出。  

如果数据量较少，传统机器学习分块模型所构成的流水线效果会很不错。但如果训练样本足够大，并且训练出的神经网络模型足够复杂，那么端到端深度学习模型的性能会比传统机器学习分块模型更好。而如果数据集规模适中，还是可以使用流水线方法，但是可以混合端到端深度学习，通过神经网络绕过某些模块，直接输出某些特征。 

![1659076726566](C:\Users\17799\AppData\Roaming\Typora\typora-user-images\1659076726566.png)

##### 6.2 使用端到端深度学习

端到端学习的优点：

①只要有足够多的数据，剩下的全部交给一个足够大的神经网络。比起传统的机器学习分块模型，可能更能捕获数据中的任何统计信息，而不需要用人类固有的认知（或者说，成见）来进行分析；

②所需手工设计的组件更少，简化设计工作流程；

缺点：

①需要大量的数据；

②排除了可能有用的人工设计组件；

决定一个问题是否应用端到端学习的**关键点**是：是否有足够的数据，支持能够直接学习从 x 映射到 y 并且足够复杂的函数。 