# 惊蛰学习笔记第七周

[TOC]

## 1.神经形态数据集处理

手动下载数据集后，获取Event数据，结果如下所示：

![1660360506318](https://github.com/LinkWithMe/summerHW/blob/main/Week9/image/1)

文件夹中新多出的文件夹：

![1660360552992](https://github.com/LinkWithMe/summerHW/blob/main/Week9/image/2)

打印一个数据，其中 `event` 使用字典格式存储Events数据，键为 `['t', 'x', 'y', 'p']`；`label` 是数据的标签，DVS128 Gesture共有11类：

![1660360646825](https://github.com/LinkWithMe/summerHW/blob/main/Week9/image/3)

获取Frame数据，将Event数据转化为Frame数据集，均匀地划分为 frames_num=20 ，运行结果如下：

![1660361727661](https://github.com/LinkWithMe/summerHW/blob/main/Week9/image/4)

新出现的文件夹：

![1660361754402](https://github.com/LinkWithMe/summerHW/blob/main/Week9/image/5)

打印一个数据：

![1660362174047](https://github.com/LinkWithMe/summerHW/blob/main/Week9/image/6)

查看一个积分好的Frame数据：

![1660362187727](https://github.com/LinkWithMe/summerHW/blob/main/Week9/image/7)

固定时间间隔积分

使用固定时间间隔积分，更符合实际物理系统。例如每 `10 ms` 积分一次，则长度为 `L ms` 的数据，可以得到 `math.floor(L / 10)` 帧。神经形态数据集中每个样本的长度往往不相同，因此会得到不同长度的帧数据。使用惊蜇框架提供的pad_sequence_collate和padded_sequence_mask可以很方便的对不等长数据进行对齐和还原。  输出如下：

![1660362626317](https://github.com/LinkWithMe/summerHW/blob/main/Week9/image/8)

自定义积分方法

惊蜇框架支持用户自定义积分方法。用户只需要提供积分函数 `custom_integrate_function` 以及保存frames的文件夹名 `custom_integrated_frames_dir_name`。 

`custom_integrate_function` 是用户定义的函数，输入是 `events, H, W` ：

- events： 一个pythono字典，键为 `['t', 'x', 'y', 'p']` 值为 `numpy.ndarray` 类型。 
- H：数据高度
- W：数据宽度

对于DVS手势数据集，H=128，W=128，函数的返回值为frames

 `custom_integrated_frames_dir_name` 可以为 `None`，在这种情况下，保存frames的文件夹名会被设置成 `custom_integrate_function.__name__`。 

选择积分方式，随机将全部events一分为二，然后积分成2帧，可以定义函数并创建数据集，结果：

![1660373825947](https://github.com/LinkWithMe/summerHW/blob/main/Week9/image/9)

在文件目录中出现新的文件夹：

![1660373979170](https://github.com/LinkWithMe/summerHW/blob/main/Week9/image/10)

查看积分结果如下：

![1660374030917](https://github.com/LinkWithMe/summerHW/blob/main/Week9/image/11)

## 2.分类DVS Gesture

使用SNN对所构建的神经形态数据集进行分类

使用的网络结构如下：

![1660374243078](https://github.com/LinkWithMe/summerHW/blob/main/Week9/image/12)

网络在 spikingjelly.activation_based.model.parametric_lif_net中进行了定义，通过文档和源码来进行学习和自己代码的编写，来进行实验。

实验结果如下：

模型参数：

![1660400149424](https://github.com/LinkWithMe/summerHW/blob/main/Week9/image/13)

实验参数设置如下：

```Python
Namespace(T=8, device='cuda:0', b=4, epochs=20, j=2, data_dir='D:\\mydataset\\DVS128Gesture', out_dir='./logs_fashion_mnist', resume=None, cupy=False, amp=False, opt='adam', momentum=0.9, lr=0.1, tau=2.0, channels=32)
```

结果：

![1660403310353](https://github.com/LinkWithMe/summerHW/blob/main/Week9/image/14)

正确率图像：

训练集：

![1660403401078](https://github.com/LinkWithMe/summerHW/blob/main/Week9/image/15)

测试集：

![1660403432893](https://github.com/LinkWithMe/summerHW/blob/main/Week9/image/16)

## 3.自连接和有状态突触

自连接模块

自连接指的是从输出到输入的连接，使用SpikingJelly框架很容易构建出带有自连接的模块。我们给神经元增加一个回路，使得它在 t 时刻的输出 s[t]，会与下一个时刻的外界输入 x[t+1] 相加，共同作为输入。可以通过 `spikingjelly.activation_based.layer.ElementWiseRecurrentContainer` 轻松实现。 `ElementWiseRecurrentContainer` 是一个包装器，可以给任意的sub_module增加一层额外的自连接。

可以发现，由于存在自连接，即便 t≥1 时 x[t]=0，由于输出的脉冲能传回到输入，神经元也能持续释放脉冲。可以使用 `spikingjelly.activation_based.layer.LinearRecurrentContainer`实现更复杂的全连接形式的自连接。

有状态的突触

将 `spikingjelly.activation_based.layer.SynapseFilter`放在普通无状 态突触的后面，对突触输出的电流进行滤波，就可以得到有状态的突触。

`StatefulSynapseNet` 和 `FeedBackNet` 的性能都高于 `PlainNet`，表明自连接和有状态突触都有助于提升网络的记忆能力。 

## 4.训练大规模SNN

在 `spikingjelly.activation_based.model`中定义了一些经典网络模型，可以直接拿来使用，使用方法与 `torchvision.models` 类似。 

SpikingJelly按照 `torchvision` 中的ResNet结构搭建的Spiking ResNet，保持了 `state_dict().keys()` 相同，因此支持直接加载预训练权重，设置 `pretrained=True` 即可。

`spikingjelly.activation_based.model.train_classify` 是根据torchvision 0.12 references 的分类代码进行改动而来，使用这个模块可以很方便的进行训练：

`spikingjelly.activation_based.model.train_classify.Trainer` 提供了较为灵活的训练方式，预留了一些接口给用户改动。例如，`spikingjelly.activation_based.model.train_classify.Trainer.set_optimizer` 定义了如何设置优化器。对于新增的优化器，只需要继承并重写此方法。

`Trainer` 在训练中会自动计算训练集、测试集的 `Acc@1, Acc@5, loss` 并使用 `tensorboard` 保存为日志文件，此外训练过程中的最新一个epoch的模型以及测试集性能最高的模型也会被保存下来。 `Trainer` 支持Distributed Data Parallel训练。 

`Trainer` 默认的数据加载函数 `load_data` 加载 ImageNet [2](https://spikingjelly.readthedocs.io/zh_CN/latest/activation_based/train_large_scale_snn.html#id3) 数据集。结合 `Trainer` 和 `spikingjelly.activation_based.model.spiking_resnet`，我们可以轻松训练大型深度SNN。

一些代码练习都放在Jupyter中进行。

## 5.实验遇到问题及解决

### 5.1 显存不够

实验中，遇到了经典的显存不够问题，如下：

![1660379551402](https://github.com/LinkWithMe/summerHW/blob/main/Week9/image/17)

上次遇到该问题是在跑GAT模型时出现的问题，当时通过缩小数据量以及在kaggle跑16GB显存完成了实验，先前学习了amp有降低显存的效果，打算用amp进行尝试：

![1660379737420](https://github.com/LinkWithMe/summerHW/blob/main/Week9/image/18)

可见，开启amp之后，显存需要，从**2G->1G**，缩小了一半，但参数还是太多

尝试时间换空间，缩小每一次的batch size和channel通道数

![1660379892094](C:\Users\17799\AppData\Roaming\Typora\typora-user-images\1660379892094.png)

### 5.2 损失函数不进行更新

在开始实验时，产生以下警告：

![1660393211069](C:\Users\17799\AppData\Roaming\Typora\typora-user-images\1660393211069.png)

按照提示进行更改，lr_scheduler.step()为调整学习率机制，将其放至每一个epoch最后：

![1660396067745](C:\Users\17799\AppData\Roaming\Typora\typora-user-images\1660396067745.png)

放至每一个epoch最后，但是仍然提示我该方法在optimizer.step()之前。

将该方法删除，损失函数loss仍不变。

训练代码与CSNN训练Fashion-MNIST部分的代码相同，唯一区别在于这次实验使用了**amp**，amp会调整模型在运算过程中的精度，是否因为amp导致了梯度的不更新？

验证猜想，关闭了amp功能，实验成功运行，部分代码如下：

```python
# 混合精度运算
if scaler is not None:
    # amp代码
    with amp.autocast():
        out_fr = net(frame).mean(0)
        loss = F.mse_loss(out_fr, label_onehot)
    scaler.scale(loss).backward()
    scaler.step(optimizer)
    scaler.update()
else:
    # 不使用amp的代码
    out_fr = net(frame).mean(0)
    loss = F.mse_loss(out_fr, label_onehot)
    loss.backward()
    optimizer.step()
```

这部分代码与惊蛰中的源代码相同，难道真的是因为amp的问题？
