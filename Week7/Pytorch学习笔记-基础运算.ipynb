{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "165952ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入包\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "352fec3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.4879e-05,  4.5848e-41, -2.3110e+08],\n",
      "        [ 3.0949e-41,  8.0519e-42,  3.6265e-38],\n",
      "        [ 7.6362e-28,  2.5353e+30,  4.5682e-43],\n",
      "        [ 6.2582e-42,  2.5205e-39,  7.8194e-25],\n",
      "        [ 2.5353e+30,  5.2268e-43,  4.1058e-42]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor（张量），NumPy 的 ndarray ，但还可以在 GPU 上使用来加速计算\n",
    "# 创建一个没有初始化的 5 * 3 矩阵：\n",
    "x=torch.empty(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb442632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5024, 0.8874, 0.1422],\n",
      "        [0.8737, 0.0718, 0.2871],\n",
      "        [0.4131, 0.9910, 0.6148],\n",
      "        [0.5146, 0.8731, 0.3427],\n",
      "        [0.1783, 0.1809, 0.3206]])\n"
     ]
    }
   ],
   "source": [
    "# 创建随机初始化矩阵\n",
    "x=torch.rand(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e542604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# 构造一个填满 0 且数据类型为 long 的矩阵\n",
    "x=torch.zeros(5,3,dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "707fac28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "# 从数据构造张量\n",
    "x=torch.tensor([5.5,3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a46f4ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[ 0.3899,  1.4075,  0.4371],\n",
      "        [-0.7676, -1.3429, -0.7746],\n",
      "        [ 1.1455, -0.1640, -0.2900],\n",
      "        [-1.2693,  0.6132,  1.5849],\n",
      "        [-0.3962,  0.0232,  0.9026]])\n",
      "torch.Size([5, 3])\n",
      "tensor([[ 0.9015,  1.4626,  1.4232],\n",
      "        [-0.7093, -0.6240, -0.5052],\n",
      "        [ 1.7322,  0.2324, -0.2443],\n",
      "        [-0.9972,  1.2347,  1.5986],\n",
      "        [ 0.5572,  0.0422,  1.7399]])\n"
     ]
    }
   ],
   "source": [
    "# 根据现有的 tensor 建立新的 tensor 。\n",
    "# 除非用户提供新的值，否则这些方法将重用输入张量的属性，例如 dtype 等：\n",
    "x=x.new_ones(5,3,dtype=torch.double)\n",
    "print(x)\n",
    "x= torch.randn_like(x,dtype=torch.float)\n",
    "print(x)\n",
    "# 获取张量形状\n",
    "print(x.size())\n",
    "\n",
    "# 运算\n",
    "# 加法1\n",
    "y=torch.rand(5,3)\n",
    "print(x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52ea1cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[-0.7336, -2.9922, -0.7091],\n",
      "        [-0.4069,  0.0747, -0.8170],\n",
      "        [-0.1389, -0.6014, -0.5661],\n",
      "        [ 0.5452,  2.0737,  0.4815],\n",
      "        [-0.3291, -1.2178, -0.8690]])\n",
      "tensor([[ 0.1003, -2.2846, -0.4287],\n",
      "        [-0.1647,  0.4394,  0.0040],\n",
      "        [ 0.5186, -0.4379, -0.2009],\n",
      "        [ 0.9509,  2.3721,  0.8443],\n",
      "        [ 0.6170, -0.3416,  0.0879]])\n",
      "tensor([[ 0.1003, -2.2846, -0.4287],\n",
      "        [-0.1647,  0.4394,  0.0040],\n",
      "        [ 0.5186, -0.4379, -0.2009],\n",
      "        [ 0.9509,  2.3721,  0.8443],\n",
      "        [ 0.6170, -0.3416,  0.0879]])\n",
      "tensor([[ 0.1003, -2.2846, -0.4287],\n",
      "        [-0.1647,  0.4394,  0.0040],\n",
      "        [ 0.5186, -0.4379, -0.2009],\n",
      "        [ 0.9509,  2.3721,  0.8443],\n",
      "        [ 0.6170, -0.3416,  0.0879]])\n"
     ]
    }
   ],
   "source": [
    "# 根据现有的 tensor 建立新的 tensor 。\n",
    "# 除非用户提供新的值，否则这些方法将重用输入张量的属性，例如 dtype 等：\n",
    "x=x.new_ones(5,3,dtype=torch.double)\n",
    "print(x)\n",
    "x= torch.randn_like(x,dtype=torch.float)\n",
    "print(x)\n",
    "\n",
    "# 运算\n",
    "# 加法1\n",
    "y=torch.rand(5,3)\n",
    "print(x+y)\n",
    "\n",
    "# 加法2\n",
    "print(torch.add(x,y))\n",
    "\n",
    "# 给定一个输出张量作为参数\n",
    "result=torch.empty(5,3)\n",
    "torch.add(x,y,out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ed33c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1003, -2.2846, -0.4287],\n",
      "        [-0.1647,  0.4394,  0.0040],\n",
      "        [ 0.5186, -0.4379, -0.2009],\n",
      "        [ 0.9509,  2.3721,  0.8443],\n",
      "        [ 0.6170, -0.3416,  0.0879]])\n"
     ]
    }
   ],
   "source": [
    "# 就地操作\n",
    "# 任何一个就地改变张量的操作后面都固定一个 _ 。例如 x.copy_（y）， x.t_（）将更改x\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "300ef5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8346,  0.6249,  0.4447,  0.1674],\n",
      "        [-0.6641,  1.2031,  0.8362, -1.3738],\n",
      "        [-0.6558, -2.0685,  0.0553, -1.5611],\n",
      "        [-1.4757,  0.9120, -0.3996,  0.2156]])\n",
      "tensor([ 0.6249,  1.2031, -2.0685,  0.9120])\n",
      "torch.Size([16]) torch.Size([5, 3]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "# 索引操作\n",
    "x=torch.randn(4,4)\n",
    "print(x)\n",
    "print(x[:,1]) #第一列\n",
    "# 改变形状\n",
    "x=x.view(16)\n",
    "z=x.view(-1,8)\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9566b351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0664])\n",
      "0.06638932228088379\n"
     ]
    }
   ],
   "source": [
    "# 如果是仅包含一个元素的 tensor，可以使用 .item（） 来得到对应的 python 数值\n",
    "x=torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "435fa5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "# torch->numpy\n",
    "a=torch.ones(5)\n",
    "print(a)\n",
    "b=a.numpy()\n",
    "print(b)\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed4e28b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# numpy->torch\n",
    "# CPU上的所有张量（ CharTensor 除外）都支持与 Numpy 的相互转换\n",
    "a=np.ones(5)\n",
    "b=torch.from_numpy(a)\n",
    "np.add(a,1,out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "763d7abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0664], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# 当GPU可用时,我们可以运行以下代码\n",
    "# 我们将使用`torch.device`来将tensor移入和移出GPU\n",
    "if torch.cuda.is_available():\n",
    "    device=torch.device(\"cuda\")\n",
    "    y = torch.ones_like(x, device=device)  # 直接在GPU上创建tensor\n",
    "    x=x.to(device)\n",
    "    z=x+y\n",
    "    print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c3fe338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "<AddBackward0 object at 0x7fcd862069b0>\n",
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 创建一个张量并设置requires_grad=True用来追踪其计算历史\n",
    "x=torch.ones(2,2,requires_grad=True)\n",
    "print(x)\n",
    "y=x+2\n",
    "print(y)\n",
    "# y是计算的结果，所以它有grad_fn属性\n",
    "print(y.grad_fn)\n",
    "\n",
    "z=y*y*3\n",
    "out=z.mean()\n",
    "print(z,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3498ee13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "<SumBackward0 object at 0x7f9dc16cbac0>\n"
     ]
    }
   ],
   "source": [
    "# .requires_grad_(...) 原地改变了现有张量的 requires_grad 标志。\n",
    "# 如果没有指定的话，默认输入的这个标志是False。\n",
    "a=torch.randn(2,2)\n",
    "a=((a*3)/(a-1))\n",
    "print(a.requires_grad)\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "b = (a * a).sum()\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5769ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 611.9094,  856.8845, -799.6572], grad_fn=<MulBackward0>)\n",
      "tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])\n"
     ]
    }
   ],
   "source": [
    "# 雅可比向量积的例子\n",
    "x=torch.randn(3,requires_grad=True)\n",
    "y=x*2\n",
    "while y.data.norm() < 1000:\n",
    "    y=y*2\n",
    "print(y)\n",
    "\n",
    "# 在这种情况下，y不再是标量。torch.autograd不能直接计算完整的雅可比矩阵\n",
    "# 只想要雅可比向量积，只需将这个向量作为参数传给backward\n",
    "v=torch.tensor([0.1,1.0,0.0001],dtype=torch.float)\n",
    "y.backward(v)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbad8e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# 为了防止跟踪历史记录（和使用内存），可以将代码块包装在with torch.no_grad():中\n",
    "# 在评估模型时特别有用\n",
    "# 来阻止autograd跟踪\n",
    "print(x.requires_grad)\n",
    "print((x ** 2).requires_grad)\n",
    "with torch.no_grad():\n",
    "    print((x ** 2).requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cf00cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn包则依赖于autograd包来定义模型并对它们求导。\n",
    "# 一个nn.Module包含各个层和一个forward(input)方法，该方法返回output\n",
    "class Net(nn.Module):\n",
    "    def init(self):\n",
    "        super(Net,self).init()\n",
    "        # 输入图像channel：1；输出channel：6；5x5卷积核\n",
    "        self.conv1=nn.Conv2d(1,6,5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        # 2x2 Max pooling\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # 如果是方阵,则可以只使用一个数字进行定义\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
